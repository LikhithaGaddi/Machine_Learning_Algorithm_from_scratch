{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nncP5eQd0IXL"
   },
   "source": [
    "# REGRESSION\n",
    "\n",
    "Please find the Diamond Price Prediction Data set https://drive.google.com/drive/folders/1qE1tm3Ke3uotTyv6SUqruI09t-AkcwRK?usp=sharing. \"description.txt\" contains the feature description of data, \"diamonds.csv\" has the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EhFbx6v-4SP8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53940</td>\n",
       "      <td>53940</td>\n",
       "      <td>53940</td>\n",
       "      <td>53940</td>\n",
       "      <td>53940</td>\n",
       "      <td>53940</td>\n",
       "      <td>53940</td>\n",
       "      <td>53940</td>\n",
       "      <td>53940</td>\n",
       "      <td>53940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>273</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>184</td>\n",
       "      <td>127</td>\n",
       "      <td>11602</td>\n",
       "      <td>554</td>\n",
       "      <td>552</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0.3</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62</td>\n",
       "      <td>56</td>\n",
       "      <td>605</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.34</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2604</td>\n",
       "      <td>21551</td>\n",
       "      <td>11292</td>\n",
       "      <td>13065</td>\n",
       "      <td>2239</td>\n",
       "      <td>9881</td>\n",
       "      <td>132</td>\n",
       "      <td>448</td>\n",
       "      <td>437</td>\n",
       "      <td>767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        carat    cut  color clarity  depth  table  price      x      y      z\n",
       "count   53940  53940  53940   53940  53940  53940  53940  53940  53940  53940\n",
       "unique    273      5      7       8    184    127  11602    554    552    375\n",
       "top       0.3  Ideal      G     SI1     62     56    605   4.37   4.34    2.7\n",
       "freq     2604  21551  11292   13065   2239   9881    132    448    437    767"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%config IPCompleter.greedy=False\n",
    "\n",
    "# To read data from diamonds.csv\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "from pprint import pprint\n",
    "import statistics\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "headers = [\"carat\",\t\"cut\",\"color\",\"clarity\",\"depth\",\"table\",\"price\",\"x\",\"y\",\"z\"]\n",
    "data = pd.read_csv('Regression_Diamonds_data/diamonds.csv', na_values='?',    \n",
    "         header=None,  names = headers) \n",
    "data = data.reset_index(drop=True)\n",
    "data = data.iloc[1:]\n",
    "data.describe()\n",
    "#print(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the dataset:\n",
    "\n",
    "1. We have both categorical and numerical data \n",
    "2. For columns cut,color and clarity we have categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p64BQ-W3zpkM"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "**KNN Regression [Diamond Price Prediction Dataset]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pi5z3DDg04cc"
   },
   "source": [
    "1. a) Build a knn regression algorithm [using only python from scratch] to predict the price of diamonds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53940 entries, 1 to 53940\n",
      "Data columns (total 10 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   carat    53940 non-null  object\n",
      " 1   cut      53940 non-null  object\n",
      " 2   color    53940 non-null  object\n",
      " 3   clarity  53940 non-null  object\n",
      " 4   depth    53940 non-null  object\n",
      " 5   table    53940 non-null  object\n",
      " 6   price    53940 non-null  object\n",
      " 7   x        53940 non-null  object\n",
      " 8   y        53940 non-null  object\n",
      " 9   z        53940 non-null  object\n",
      "dtypes: object(10)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "\n",
    "1. As the non null values in all columns are same. We can say there are no null values in the given data set\n",
    "2. Price is the target value, that has to be predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for categorical data and convert to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ideal        21551\n",
       "Premium      13791\n",
       "Very Good    12082\n",
       "Good          4906\n",
       "Fair          1610\n",
       "Name: cut, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.cut.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G    11292\n",
       "E     9797\n",
       "F     9542\n",
       "H     8304\n",
       "D     6775\n",
       "I     5422\n",
       "J     2808\n",
       "Name: color, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.color.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SI1     13065\n",
       "VS2     12258\n",
       "SI2      9194\n",
       "VS1      8171\n",
       "VVS2     5066\n",
       "VVS1     3655\n",
       "IF       1790\n",
       "I1        741\n",
       "Name: clarity, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.clarity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as the categorical data is converted into numerical, we can continue training the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# enc = OrdinalEncoder()\n",
    "cut_mapper = {\"Fair\":1,\"Good\":2,\"Very Good\":3,\"Premium\":4,\"Ideal\":5}\n",
    "color_mapper = {\"D\":7,\"E\":6,\"F\":5,\"G\":4,\"H\":3,\"I\":2,\"J\":1}\n",
    "clarity_mapper = {\"I1\":1,\"SI2\":2,\"SI1\":3,\"VS2\":4,\"VS1\":5,\"VVS2\":6,\"VVS1\":7,\"IF\":8}\n",
    "# enc.fit(X)\n",
    "data['cut'] = data['cut'].replace(cut_mapper)\n",
    "data['color'] = data['color'].replace(color_mapper)\n",
    "data['clarity'] = data['clarity'].replace(clarity_mapper)\n",
    "\n",
    "\n",
    "\n",
    "keys = [\"carat\",\"depth\",\"price\",\"table\",\"x\",\"y\",\"z\"]\n",
    "index_non_categorical = [0,4,5,6,6,7,8]\n",
    "for x in keys:\n",
    "    data[x] = [float(item) for item in data[x]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlPGwmq2elOR"
   },
   "source": [
    "# **Linear Regression**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DB9Co3225uTa"
   },
   "source": [
    "2a) Implement a Linear Regression model (from the scratch) taking suitable independent variables from the dataset. \n",
    "\n",
    "Report and Calculate the error obtained.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As depth is a column which is dependent of x,y and z. We don't need to use that as it can be derived from the coefficients of the columns x,y and z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "wsckTq4zzxnx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  130098736.68409386\n",
      "MAE:  10655.156363198716\n",
      "r_score: 0.0036858653638780913\n"
     ]
    }
   ],
   "source": [
    "def hypothesis(theta,X,constant):\n",
    "    return constant + (np.dot(X,theta.T))\n",
    "\n",
    "def cost_function(theta,X,y,m,constant):\n",
    "    d = np.sum((hypothesis(theta,X,constant)-y)**2)\n",
    "    d/=(2*m)\n",
    "    return d\n",
    "\n",
    "def gradient_descent(theta,X,y,m,epochs,alpha,constant):\n",
    "    i = 0\n",
    "    cost = []\n",
    "    while i<epochs:\n",
    "        h = hypothesis(theta,X,constant)\n",
    "        z = h - y\n",
    "        constant = constant - ((alpha)*(np.sum(z)))/m\n",
    "        theta = theta - ((alpha)*(np.sum(np.dot(X.T,z),axis=0)))/m\n",
    "        cost.append(cost_function(theta,X,y,m,constant))\n",
    "        i+=1\n",
    "    return theta,cost,constant\n",
    "\n",
    "\n",
    "def predict(X,y,test):\n",
    "    m = len(X)\n",
    "\n",
    "    temp = 0.005\n",
    "    theta = np.repeat(temp,len(X[0]))\n",
    "    \n",
    "    aplha = 0.00005\n",
    "    epochs = 10000\n",
    "    \n",
    "    theta,cost,constant = gradient_descent(theta,X,y,m,10,0.01,0.0000001)\n",
    "    y_predict = hypothesis(theta,test,constant)\n",
    "    return (y_predict)\n",
    "\n",
    "\n",
    "\n",
    "y_predict_LR = predict(X_train,y_train,X_test)\n",
    "\n",
    "error = r_squared(y_predict_LR,y_test)\n",
    "\n",
    "display_error(y_predict_LR,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PUfKXGU6DQ2"
   },
   "source": [
    "2b) What are the best suitable features you used to predict the price of the dataset and Why?\n",
    "\n",
    "Idea: Use Correlation to get the suitable features and Report the values accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best suitable features are the one which are highly correlated with the price(column to be predicted). So we can filter them by using the corr() function and then deduce the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "nUVKOe6d6g2u",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#code for Correlation between features and the Diamond Price.\n",
    "def plot_graph(corr):\n",
    "    sns.heatmap(corr, \n",
    "            xticklabels=corr.columns,\n",
    "            yticklabels=corr.columns)\n",
    "\n",
    "corr = data.corr()\n",
    "plot_graph(corr)\n",
    "\n",
    "\n",
    "columns = np.full((corr.shape[0],), True, dtype=bool)\n",
    "\n",
    "\n",
    "for i in range(0, corr.shape[0]):\n",
    "    if(abs(corr.iloc[i,6])<0.2):\n",
    "        columns[i] = False\n",
    "                \n",
    "selected_columns = data.columns[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations:\n",
    "\n",
    "We conclude that two columns are closely related if the correlation value between them is near to (+1 or -1)\n",
    "Here the columns carat,x,y and z are closely related to the column price. which is the value we have to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let us run the algorithm by only considering the columns which are closely related to price\n",
    "\n",
    "X = data[selected_columns]\n",
    "y = data['price']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_correlation, X_test_correlation, y_train_correlation, y_test_correlation = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "\n",
    "X_train_correlation = X_train_correlation.to_numpy()\n",
    "X_test_correlation = X_test_correlation.to_numpy()\n",
    "y_train_correlation = y_train_correlation.to_numpy()\n",
    "y_test_correlation = y_test_correlation.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  2.9655425443086803e+117\n",
      "MAE:  3.8314863624980054e+58\n",
      "r_score: 0.9999998548499477\n"
     ]
    }
   ],
   "source": [
    "y_predict_correlation = predict(X_train_correlation,y_train_correlation,X_test_correlation)\n",
    "display_error(y_predict_correlation,y_test_correlation)\n",
    "\n",
    "MSE = mean_square_error(y_predict_correlation,y_test_correlation)\n",
    "MAE = mean_absolute_error(y_predict_correlation,y_test_correlation)\n",
    "R2_score = r_squared(y_predict_correlation,y_test_correlation)\n",
    "scores2 = [MSE,MAE,R2_score]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observation:\n",
    "\n",
    "We can observe that by considering only closely related values we get more accuracy(r-squared value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QB-vCqz6u5z"
   },
   "source": [
    "Explanation for 2b) - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNDl68N26yY3"
   },
   "source": [
    "2c) Use the module Linear Regression from sklearn to predict the price of diamonds(considering the same attributes as before) and compare the result obtained with the above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "50xYhwND64tM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  3.319760798049055e-24\n",
      "MAE:  1.4464932362353298e-12\n",
      "r_score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# import sklearn model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "regr = LinearRegression() \n",
    "  \n",
    "regr.fit(X_train_correlation, y_train_correlation) \n",
    "y_predict = regr.predict(X_test_correlation) \n",
    "display_error(y_predict,y_test_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = mean_square_error(y_predict_correlation,y_test_correlation)\n",
    "MAE = mean_absolute_error(y_predict_correlation,y_test_correlation)\n",
    "R2_score = r_squared(y_predict_correlation,y_test_correlation)\n",
    "scores1 = [MSE,MAE,R2_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                 MSE          MAE    R2\n",
      "-----------  ------------  -----------  ----\n",
      "Implemented  2.96554e+117  3.83149e+58     1\n",
      "sklearn      2.96554e+117  3.83149e+58     1\n"
     ]
    }
   ],
   "source": [
    "tabular_data=[[\"Implemented\"]+scores2,[\"sklearn\"]+scores1]\n",
    "print(tabulate(tabular_data, headers=['Model','MSE','MAE','R2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "121Z4wwx7CLk"
   },
   "source": [
    "2d) Now, using the whole dataset, predict the price of the Diamonds using the module of Linear Regression from sklearn. Report the changes you have observed compared to before? Adding extra features did it make the prediction better or worse.Comment? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Eo1pB2QB7Jqz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  2002297.6958848173\n",
      "MAE:  957.0703249562245\n",
      "r_score: 0.9089345519564922\n"
     ]
    }
   ],
   "source": [
    "regr.fit(X_train, y_train) \n",
    "y_predict = regr.predict(X_test) \n",
    "display_error(y_predict,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAqKLuCh7qP5"
   },
   "source": [
    "2e) Now, compare the algorithms KNN regression and Linear Regression. What are the differences you have observed? Which is better and why. Your statements should be backed up with statistics. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                            MSE            MAE        R2\n",
      "-----------------  -----------------  -------------  --------\n",
      "Linear regression       2.96554e+117    3.83149e+58  1\n",
      "KNN regression     839878             456.912        0.947759\n"
     ]
    }
   ],
   "source": [
    "score3 = [mean_square_error2, mean_absolute_error2, r_squared2]\n",
    "\n",
    "tabular_data=[[\"Linear regression\"]+scores2,[\"KNN regression\"]+score3]\n",
    "print(tabulate(tabular_data, headers=['Model','MSE','MAE','R2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is a prametric approach beacuse it assumes a linear functional form of f(X) where as kNN is a non-parametric method.\n",
    "\n",
    "Advantages of Linear regression here we only need to estimate a small number of coefiicients. Often easy to interpret. But it makes strong assumptions about the form of f(X). Suppose we assume a linear relationship between X and Y but the true relationship is far from lienar, then the resulting model will provide a poor fit to the data, and any conclusions drawn from it will be a suspect. \n",
    "\n",
    "When it comes to KNN it don't assume an explicit form for f(X), providing a more flexible approach. But this can often be more complex to understand and interpret. Also takes more time for computation. So called as lazy-learning algorithm.\n",
    "\n",
    "\n",
    "If there are small number of observations per predictor, then linear regression method works better. \n",
    "\n",
    "But one advantage of KNN is that we don't have to train the data prior. So we keep on adding the data. \n",
    "\n",
    "For this particular example, I got more accuracy for linear regression. So I prefer that over KNN. We can choose which algorithm to proceed with before starting the implementation. If we are not satisfied with the results, we can always go with other algorithms. \n",
    "\n",
    "We have to make sure whatever the algorithm we are choosing, the data should be shaped so that it satisfies the assumptions made by the algorithm. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "6poNZp96z1gN"
   ],
   "name": "SMAI -Assignment1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
